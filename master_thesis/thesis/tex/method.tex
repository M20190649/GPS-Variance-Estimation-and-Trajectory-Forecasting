\chapter{Method}
\label{cha:method}

% The method used is covered in this chapter.
% First, an exploratory data analysis (EDA) was performed to learn about the structure of the features.
% After the EDA, the features were partitioned into two sets: a training set and a test set.
% The training set contained 80\% of all the features and their respective labels (benign or malicious).
% The test set contained the remaining 20\% of the data set.
% The training set, together with the respective labels, were then used to train the NB, SVM, RF and CNN classifiers.
% Finally, the classifiers were evaluated on the test set with the metrics defined in Section \ref{sec:eval-metrics}.
% The labels in the test set are the true values that the classifiers should try and predict.
% Thus, the evaluation metrics are calculated with the predicted (classified) test labels and the true test labels.
% The evaluation metrics for all the classifiers were then compared to each other.

% \section{Exploratory Data Analysis}
% This work used static Android Package Kit (APK) features to train the classifiers.
% Even though the features already consisted of aggregated data, an exploratory data analysis (EDA) was still performed.
% The reason behind this is that an EDA can, for example, capture hidden information in the features that might otherwise be difficult to find.

% The EDA applied in this work is based on the techniques covered in \cite{Gelman2003, Hoaglin2003, Tukey1977, Velleman1981}.
% The interactive techniques in \cite{Anselin1999} were not used in this work, as the data set does not contain spatial data.

% The first step of the EDA was to visualise the static APK features in plots.
% The plots were then analysed and potential outliers were documented and explored.
% The exploration of outliers is necessary, as outliers might carry useful information that need to be analysed before generalising the model.
% Thus, the outcome of the EDA was plots visualising the structure of the static APK features, the documentation of outliers, and the preprocessing (e.g., smoothing) of the APK features.
% It was also used as a basis to find redundant features which would only increase the complexity of the classification models, without improving the results.

% EDA was also used as a basis when discussing alternative features to use, other than the static APK features.
% The discussion on alternative features was also heavily based on the presented material in Chapter \ref{cha:related-work}.

% The EDA performed was affected by the limited data set used in this work.
% The data set only contained static features extracted from the \texttt{.apk} files of a limited set of applications.
% It is infeasible to create a dataset of all existing Android applications, as they have to be manually labelled as either malicious or benign.
% The features used in \cite{Alam2013, Liang2014, Mahindru2017, Yerima2015, Zhao2011} combined static features with features dynamically collected at runtime.
% The static limitation of the features in this work probably affected the machine learning models implemented and the results obtained.

% \section{Naive Bayes}
% The first step after performing the EDA was to train a simple NB classifier in order to achieve a simple baseline.
% The NB classifier was then evaluated on the test set by calculating the metrics defined in Section \ref{sec:eval-metrics}.
% The NB was also evaluated with the cross-entropy metric, since the NB classifier generally outputs a posterior distribution.
% The NB used the implementation found in the scikit-learn\footnote{http://scikit-learn.org/stable/index.html} framework.

% The WNBC, covered in Section \ref{sec:WNBC}, was not used in this work, as it was not supported by the scikit-learn framework.
% The WNBC would also, as previously discussed, add a computational overhead to the system and increase the complexity of the model.
% Thus, the WNBC was deemed out-of-scope for this work. 

% \section{Support Vector Machines}
% The next step was to train a SVM classifier on the static features.
% The training process required the use of cross-validation to optimise the parameters.
% Various kernels, e.g., the RBF kernel and the polynomial kernel, were explored and their respective parameters optimised.
% The final SVM model then classified the test data set and the evaluation metrics were calculated from the results.
% The cross-entropy metric can not be used on the traditional SVM model, as SVMs do not yield probability distributions as outputs.
% Hence, the cross-entropy metric was omitted for the SVM classifier.
% The SVM classifier used the scikit-learn implementation.

% The active learning SVM method used in \cite{Zhao2011} was not explored in this work, since the SVM could be trained on an already fully-labelled data set.

% \section{Random Forest}
% The training of the RF classifier required a heavy usage of cross-validation.
% Both the depth of the trees and the number of features used in each tree needed to be varied and evaluated.
% The best RF classifier was chosen once the parameter search space was adequately explored.
% The best RF was in this work defined as the one which achieved the highest cross-validation score.
% The parameter search space was considered to be adequately explored once the cross-validation score found a (local) optimum.
% The RF classifier was then evaluated on the test set and the evaluation metrics calculated.
% The method used is similar to the work done in \cite{Alam2013}.
% The RF classifier used the Python 3.6 implementation found in scikit-learn.

% \section{Convolutional Neural Networks}
% The structure of the CNN was evaluated and chosen based on the cross-validation score.
% The structure is based on the structure used in \cite{McLaughlin2017}.
% The number of hidden layers was explored together with the number of feature maps created from each layer; different output functions were explored too.
% The resulting CNN was then evaluated on the test set and the cross-entropy metric calculated.
% The CNN was implemented and trained in the PyTorch\footnote{http://pytorch.org/} framework.
